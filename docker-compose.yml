services:
  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    container_name: rtpi-postgres
    environment:
      POSTGRES_USER: rtpi
      POSTGRES_PASSWORD: rtpi
      POSTGRES_DB: rtpi_main
    ports:
      - "5434:5432"  # Changed from 5432 to avoid conflicts
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U rtpi"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - rtpi-network

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: rtpi-redis
    ports:
      - "6381:6379"  # Changed from 6379 to avoid conflicts
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - rtpi-network

  # RTPI Security Tools Container
  rtpi-tools:
    build:
      context: .
      dockerfile: Dockerfile.tools
    container_name: rtpi-tools
    network_mode: "host"
    volumes:
      - tool-results:/var/log/rtpi
      - tool-configs:/opt/tools/config
      - shared-data:/shared
    stdin_open: true
    tty: true
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "echo", "healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  # PowerShell Empire C2 Server
  empire-server:
    image: bcsecurity/empire:latest
    container_name: rtpi-empire
    ports:
      - "1337:1337"     # Empire REST API
      - "5001:5001"     # Empire Web UI (optional)
      - "8080-8100:8080-8100"  # Dynamic listener ports
    environment:
      # Database connection (shared PostgreSQL)
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_DB: rtpi_main
      POSTGRES_USER: rtpi
      POSTGRES_PASSWORD: rtpi
      # Empire configuration
      EMPIRE_USERNAME: empireadmin
      EMPIRE_PASSWORD: ${EMPIRE_PASSWORD:-ChangeMeNow123!}
      RESTPORT: 1337
      # Optional: Enable SocketIO for real-time events
      SOCKETIO_ENABLED: "true"
      SOCKETIO_PORT: 5002
    volumes:
      - empire-data:/opt/Empire/data
      - empire-downloads:/opt/Empire/downloads
      - shared-data:/shared
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - rtpi-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:1337/api/version"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # ATT&CK Workbench MongoDB Database
  workbench-db:
    image: mongo:7
    container_name: rtpi-workbench-db
    environment:
      MONGO_INITDB_ROOT_USERNAME: workbench
      MONGO_INITDB_ROOT_PASSWORD: ${WORKBENCH_DB_PASSWORD:-workbench123}
      MONGO_INITDB_DATABASE: attack-workbench
    ports:
      - "27017:27017"
    volumes:
      - workbench-db-data:/data/db
    networks:
      - rtpi-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ATT&CK Workbench REST API
  workbench-api:
    image: ghcr.io/center-for-threat-informed-defense/attack-workbench-rest-api:latest
    container_name: rtpi-workbench-api
    ports:
      - "3010:3010"
    environment:
      # MongoDB connection
      MONGODB_URL: mongodb://workbench:${WORKBENCH_DB_PASSWORD:-workbench123}@workbench-db:27017/attack-workbench?authSource=admin
      # API configuration
      PORT: 3010
      # CORS configuration - allow RTPI frontend
      CORS_ORIGIN: "http://localhost:5000,http://localhost:3000,http://localhost:3001,http://localhost:3020"
      # Session configuration
      SESSION_SECRET: ${WORKBENCH_SESSION_SECRET:-change-this-secret-key}
      # Authentication (optional)
      AUTHN_MECHANISM: anonymous
    depends_on:
      workbench-db:
        condition: service_healthy
    networks:
      - rtpi-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3010/api/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s

  # ATT&CK Workbench Frontend (Optional - for direct access)
  workbench-frontend:
    image: ghcr.io/center-for-threat-informed-defense/attack-workbench-frontend:latest
    container_name: rtpi-workbench-frontend
    ports:
      - "3020:80"
    environment:
      # API endpoint configuration
      WORKBENCH_REST_API_URL: http://workbench-api:3010/api
    depends_on:
      workbench-api:
        condition: service_healthy
    networks:
      - rtpi-network
    restart: unless-stopped
    profiles:
      - workbench-ui  # Optional profile - only start if explicitly enabled

  # ============================================================================
  # Kasm Workspaces - Browser-Based Desktop Streaming Platform
  # ============================================================================

  # Kasm PostgreSQL Database (separate from main RTPI database)
  kasm-db:
    image: kasmweb/postgres:1.17.0
    container_name: rtpi-kasm-db
    environment:
      POSTGRES_USER: kasmapp
      POSTGRES_PASSWORD: ${KASM_DB_PASSWORD:-kasm123secure}
      POSTGRES_DB: kasm
    ports:
      - "5433:5432"  # Different port to avoid conflict with main postgres
    volumes:
      - kasm-db-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U kasmapp"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - rtpi-network
    restart: unless-stopped

  # Kasm Redis Cache (separate from main RTPI Redis)
  kasm-redis:
    image: redis:5-alpine
    container_name: rtpi-kasm-redis
    ports:
      - "6380:6379"  # Different port to avoid conflict with main redis
    volumes:
      - kasm-redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - rtpi-network
    restart: unless-stopped

  # Kasm API Server - REST API for workspace management
  kasm-api:
    image: kasmweb/api:1.17.0
    container_name: rtpi-kasm-api
    environment:
      # Database connection
      DATABASE_HOSTNAME: kasm-db
      DATABASE_PORT: 5432
      DATABASE_USER: kasmapp
      DATABASE_PASSWORD: ${KASM_DB_PASSWORD:-kasm123secure}
      DATABASE_NAME: kasm
      DATABASE_SSL: "false"
      # Redis connection
      REDIS_HOSTNAME: kasm-redis
      REDIS_PORT: 6379
      # API configuration
      API_SERVER_ID: ${KASM_API_SERVER_ID:-default}
      SERVER_HOSTNAME: ${KASM_SERVER_HOSTNAME:-localhost}
      SERVER_ZONE: default
      # SSL/TLS
      HTTPS_ENABLED: "true"
      SSL_CERT_FILE: /opt/kasm/current/certs/kasm_nginx.crt
      SSL_KEY_FILE: /opt/kasm/current/certs/kasm_nginx.key
    ports:
      - "8443:443"  # Kasm HTTPS API port
    volumes:
      - kasm-api-data:/opt/kasm/current
      - kasm-certs:/opt/kasm/current/certs
    depends_on:
      kasm-db:
        condition: service_healthy
      kasm-redis:
        condition: service_healthy
    networks:
      - rtpi-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-k", "-f", "https://localhost:443/api/__healthcheck"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Kasm Manager - Workspace lifecycle management
  kasm-manager:
    image: kasmweb/manager:1.17.0
    container_name: rtpi-kasm-manager
    environment:
      # Database connection
      DATABASE_HOSTNAME: kasm-db
      DATABASE_PORT: 5432
      DATABASE_USER: kasmapp
      DATABASE_PASSWORD: ${KASM_DB_PASSWORD:-kasm123secure}
      DATABASE_NAME: kasm
      # Redis connection
      REDIS_HOSTNAME: kasm-redis
      REDIS_PORT: 6379
      # Manager configuration
      MANAGER_ID: ${KASM_MANAGER_ID:-default-manager}
      SERVER_HOSTNAME: ${KASM_SERVER_HOSTNAME:-localhost}
    volumes:
      - kasm-manager-data:/opt/kasm/current
      - /var/run/docker.sock:/var/run/docker.sock  # Docker socket for workspace management
    depends_on:
      kasm-db:
        condition: service_healthy
      kasm-redis:
        condition: service_healthy
      kasm-api:
        condition: service_healthy
    networks:
      - rtpi-network
    restart: unless-stopped

  # Kasm Proxy (Nginx) - Reverse proxy for workspace access
  kasm-proxy:
    image: nginx:alpine
    container_name: rtpi-kasm-proxy
    environment:
      - SERVER_HOSTNAME=${KASM_SERVER_HOSTNAME:-localhost}
    ports:
      - "8443:443"  # HTTPS for workspace access
      - "8080:80"   # HTTP redirect to HTTPS
    volumes:
      - kasm-proxy-config:/etc/nginx/conf.d
      - kasm-certs:/etc/nginx/certs:ro
    depends_on:
      - kasm-api
      - kasm-guac
    networks:
      - rtpi-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Kasm Guacamole - Remote desktop protocol gateway
  kasm-guac:
    image: kasmweb/kasm-guac:1.17.0
    container_name: rtpi-kasm-guac
    environment:
      # Database connection for session tracking
      POSTGRES_HOSTNAME: kasm-db
      POSTGRES_PORT: 5432
      POSTGRES_DATABASE: kasm
      POSTGRES_USER: kasmapp
      POSTGRES_PASSWORD: ${KASM_DB_PASSWORD:-kasm123secure}
      # Guacamole configuration
      GUACD_HOSTNAME: localhost
      GUACD_PORT: 4822
    ports:
      - "4822:4822"  # Guacamole daemon port
    volumes:
      - kasm-guac-data:/opt/kasm/current
    depends_on:
      kasm-db:
        condition: service_healthy
    networks:
      - rtpi-network
    restart: unless-stopped

  # Kasm Agent - Workspace provisioning and monitoring
  kasm-agent:
    image: kasmweb/agent:1.17.0
    container_name: rtpi-kasm-agent
    environment:
      # API connection
      API_HOSTNAME: kasm-api
      API_PORT: 443
      # Agent configuration
      AGENT_ID: ${KASM_AGENT_ID:-default-agent}
      SERVER_HOSTNAME: ${KASM_SERVER_HOSTNAME:-localhost}
      PUBLIC_HOSTNAME: ${KASM_PUBLIC_HOSTNAME:-localhost}
    volumes:
      - kasm-agent-data:/opt/kasm/current
      - /var/run/docker.sock:/var/run/docker.sock  # Docker socket for container management
    depends_on:
      kasm-api:
        condition: service_healthy
      kasm-manager:
        condition: service_started
    networks:
      - rtpi-network
    restart: unless-stopped

  # Kasm Share - File sharing service for workspaces
  kasm-share:
    image: kasmweb/share:1.17.0
    container_name: rtpi-kasm-share
    environment:
      # Redis connection for share tracking
      REDIS_HOSTNAME: kasm-redis
      REDIS_PORT: 6379
      # Share service configuration
      SHARE_ID: ${KASM_SHARE_ID:-default-share}
    ports:
      - "8182:8182"  # File sharing port
    volumes:
      - kasm-share-data:/opt/kasm/current/shares
    depends_on:
      kasm-redis:
        condition: service_healthy
    networks:
      - rtpi-network
    restart: unless-stopped

  # Certbot - Automated SSL/TLS certificate management
  # Supports both HTTP-01 and DNS-01 (Cloudflare) challenges
  certbot:
    image: certbot/dns-cloudflare:latest
    container_name: rtpi-certbot
    environment:
      - CERTBOT_EMAIL=${CERTBOT_EMAIL:-admin@example.com}
      - CERTBOT_DOMAIN=${KASM_SERVER_HOSTNAME:-localhost}
      # Cloudflare API token for DNS-01 challenge (#KW-12)
      - CLOUDFLARE_API_TOKEN=${CLOUDFLARE_API_TOKEN:-}
    volumes:
      - certbot-conf:/etc/letsencrypt
      - certbot-www:/var/www/certbot
      - kasm-certs:/etc/nginx/certs
      - ./scripts/ssl:/scripts/ssl:ro  # SSL automation scripts
    command: >
      sh -c "
      # Create Cloudflare credentials if API token is set
      if [ -n \"$$CLOUDFLARE_API_TOKEN\" ]; then
        echo \"dns_cloudflare_api_token = $$CLOUDFLARE_API_TOKEN\" > /etc/letsencrypt/cloudflare.ini
        chmod 600 /etc/letsencrypt/cloudflare.ini
      fi

      # Certificate renewal loop (#KW-13)
      trap exit TERM
      while :; do
        # Renew certificates expiring within 30 days
        certbot renew --quiet

        # Copy certificates to nginx directory
        if [ -d /etc/letsencrypt/live ]; then
          for domain in /etc/letsencrypt/live/*; do
            if [ -d \"$$domain\" ]; then
              domain_name=\$$(basename \"$$domain\")
              cp -L \"$$domain/fullchain.pem\" \"/etc/nginx/certs/\$${domain_name}.crt\" 2>/dev/null || true
              cp -L \"$$domain/privkey.pem\" \"/etc/nginx/certs/\$${domain_name}.key\" 2>/dev/null || true
            fi
          done
        fi

        # Renewal runs every 12 hours
        sleep 12h & wait $$!
      done
      "
    networks:
      - rtpi-network
    restart: unless-stopped
    profiles:
      - certbot  # Optional profile - only start if SSL automation is needed

  # ===========================================================================
  # Ollama AI Services (Enhancement #08 - Ollama AI Integration)
  # ===========================================================================

  # Ollama (GPU-accelerated inference)
  ollama:
    image: ollama/ollama:latest
    container_name: rtpi-ollama
    profiles:
      - gpu  # Only start if GPU is available
    ports:
      - "11434:11434"
    volumes:
      - ollama-models:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      - OLLAMA_ORIGINS=*
      - OLLAMA_NUM_PARALLEL=2
      - OLLAMA_MAX_LOADED_MODELS=2
      - OLLAMA_KEEP_ALIVE=30m  # Auto-unload after 30 min inactivity
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - rtpi-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Ollama CPU Fallback (for systems without GPU)
  ollama-cpu:
    image: ollama/ollama:latest
    container_name: rtpi-ollama-cpu
    profiles:
      - cpu  # Only start if no GPU available
    ports:
      - "11434:11434"
    volumes:
      - ollama-models:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      - OLLAMA_ORIGINS=*
      - OLLAMA_NUM_PARALLEL=1  # Limit parallelism on CPU
      - OLLAMA_MAX_LOADED_MODELS=1
      - OLLAMA_KEEP_ALIVE=30m  # Auto-unload after 30 min inactivity
      - OLLAMA_NUM_THREAD=8  # CPU threads to use
    networks:
      - rtpi-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Ollama WebUI (Model management interface)
  ollama-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: rtpi-ollama-webui
    profiles:
      - ollama-ui  # Optional - only if you want the web interface
    ports:
      - "3002:8080"  # Avoid conflict with backend port 3001
    volumes:
      - ollama-webui-data:/app/backend/data
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - WEBUI_AUTH=false  # Disable auth since it's internal
      - WEBUI_NAME=RTPI Ollama Manager
    depends_on:
      - ollama
    networks:
      - rtpi-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

# Application (Development)
#  app:
#    build:
#      context: .
#      dockerfile: Dockerfile.dev
#    container_name: rtpi-app
#    ports:
#      - "3000:3000"
#      - "5000:5000"
#    environment:
#      NODE_ENV: development
#      DATABASE_URL: postgresql://rtpi:rtpi@postgres:5432/rtpi_main
#      REDIS_URL: redis://redis:6379
#      PORT: 3000
#    volumes:
#      - .:/app
#      - /app/node_modules
#    depends_on:
#      postgres:
#        condition: service_healthy
#      redis:
#        condition: service_healthy
#    networks:
#      - rtpi-network

networks:
  rtpi-network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  tool-results:
  tool-configs:
  shared-data:
  empire-data:
  empire-downloads:
  workbench-db-data:
  # Kasm Workspaces volumes
  kasm-db-data:
  kasm-redis-data:
  kasm-api-data:
  kasm-manager-data:
  kasm-proxy-config:
  kasm-guac-data:
  kasm-agent-data:
  kasm-share-data:
  kasm-certs:
  certbot-conf:
  certbot-www:
  # Ollama AI volumes
  ollama-models:
  ollama-webui-data:
