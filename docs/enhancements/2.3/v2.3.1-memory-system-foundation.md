# Phase 1: Memory System Foundation - Detailed Plan

Perfect! Let's start with **Phase 1: Memory System Foundation**. This phase establishes the agentic memory infrastructure that all other v2.3 features will depend on.

---

## ðŸ“‹ Phase 1 Overview

**Objective:** Research, select, and architect the memory system for the RTPI agentic reporting framework.

**Duration Estimate:** 3-5 days

**Dependencies:** None (foundational phase)

---

## ðŸ” Step 1.1: Memory Framework Comparative Analysis

### Research Findings (from Tavily MCP)

I've already completed initial research on the 5 frameworks mentioned in the roadmap:

#### **1. Mem0 (RECOMMENDED)**
- **GitHub:** 46.8k stars, 5.2k forks, actively maintained
- **Architecture:** Dual vector + graph storage strategy
- **Performance:** 91% lower latency than alternatives
- **Integration:** Rich LangGraph integration, supports multiple LLM providers
- **Deployment:** Self-hosted or cloud, PostgreSQL + pgvector compatible
- **Strengths:**
  - Mature, production-ready
  - Clean, flexible API
  - Strong developer community
  - MCP compatibility potential

#### **2. Cognee**
- **Focus:** Graph-based reasoning with temporal memory
- **Architecture:** Structured memory with entity-relationship graphs
- **Strengths:**
  - World models & behavioral validation
  - MCP support (Claude Agent SDK integration)
  - Enterprise-grade reasoning
- **Consideration:** More complex, better for heavy reasoning tasks

#### **3. Letta (MemGPT)**
- **Architecture:** OS-style layered memory
- **Focus:** Long-range personalization across sessions
- **Strengths:**
  - Hierarchical memory management
  - Good for multi-session continuity
- **Consideration:** May be overkill for reporting agents

#### **4. Memori (Py.AI)**
- **Status:** Smaller project, less mature
- **Focus:** Developer-friendly framework
- **Consideration:** Requires more infrastructure management

#### **5. MemU (NevaMind-AI)**
- **Status:** Emerging project, limited documentation
- **Consideration:** Not production-ready

#### **6. agent-file (Letta's approach)**
- **Architecture:** File-based memory storage
- **Consideration:** Simpler but limited scalability

---

### Recommendation Matrix

| Criteria | Mem0 | Cognee | Letta | Memori | MemU |
|----------|------|--------|-------|--------|------|
| Maturity | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | â­â­ | â­ |
| Performance | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ | â­â­â­ | â­â­ |
| Integration | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ | â­â­ | â­ |
| Documentation | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | â­â­ | â­ |
| Community | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­ | â­ |
| **TOTAL** | **25/25** | **19/25** | **17/25** | **10/25** | **5/25** |

### **Final Recommendation: Mem0**

**Justification:**
1. **Production-Ready:** Battle-tested with 46.8k stars
2. **Performance:** 91% latency improvement critical for real-time reporting
3. **PostgreSQL Native:** Already using PostgreSQL + pgvector
4. **Flexible API:** Won't lock us into rigid patterns
5. **Active Development:** Recent updates (Feb 2026)
6. **MCP Potential:** Can be wrapped as MCP server if needed

---

## ðŸ—ï¸ Step 1.2: Architecture Design

### Memory System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RTPI Application Layer                    â”‚
â”‚  (Operations, Targets, Vulnerabilities, Reporter Agents)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Memory Service Layer                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Mem0 API   â”‚  â”‚ Memory Query â”‚  â”‚ Memory Sync  â”‚     â”‚
â”‚  â”‚   Wrapper    â”‚  â”‚   Manager    â”‚  â”‚   Manager    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Mem0 Core Engine                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  Vector Store    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”‚   Graph Store    â”‚          â”‚
â”‚  â”‚  (pgvector)      â”‚        â”‚   (PostgreSQL)   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                PostgreSQL Database (Existing)                â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚        â”‚ Memory Tables â”‚      â”‚ Vector Index  â”‚            â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Integration Points

1. **Reporter Agents** â†’ Store hourly status reports in memory
2. **Operations Manager** â†’ Query aggregated memory for synthesis
3. **Task Agents** â†’ Retrieve relevant context from memory
4. **Vulnerability Agents** â†’ Store/retrieve vulnerability patterns
5. **Surface Assessment** â†’ Store/retrieve asset discovery history

---

## ðŸ’¾ Step 1.3: Database Schema Changes

### New Tables Required

```sql
-- Migration: 0020_add_mem0_integration.sql

-- Memory contexts table
CREATE TABLE memory_contexts (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  context_type TEXT NOT NULL, -- 'operation', 'target', 'agent', 'user'
  context_id TEXT NOT NULL, -- ID of the related entity
  context_name TEXT NOT NULL,
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMP NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMP NOT NULL DEFAULT NOW(),
  UNIQUE(context_type, context_id)
);

-- Memory entries table (mem0 memories)
CREATE TABLE memory_entries (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  context_id UUID NOT NULL REFERENCES memory_contexts(id) ON DELETE CASCADE,
  mem0_memory_id TEXT UNIQUE, -- Mem0's internal ID
  
  -- Memory content
  memory_text TEXT NOT NULL,
  memory_type TEXT NOT NULL, -- 'fact', 'event', 'insight', 'pattern'
  
  -- Embeddings (for vector search)
  embedding vector(1536), -- OpenAI ada-002 dimension
  
  -- Metadata
  source_agent_id UUID REFERENCES agents(id),
  source_report_id UUID,
  relevance_score REAL DEFAULT 1.0,
  access_count INTEGER DEFAULT 0,
  last_accessed_at TIMESTAMP,
  
  -- Temporal
  valid_from TIMESTAMP NOT NULL DEFAULT NOW(),
  valid_until TIMESTAMP, -- NULL = permanent
  
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMP NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMP NOT NULL DEFAULT NOW()
);

-- Memory relationships (graph edges)
CREATE TABLE memory_relationships (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  source_memory_id UUID NOT NULL REFERENCES memory_entries(id) ON DELETE CASCADE,
  target_memory_id UUID NOT NULL REFERENCES memory_entries(id) ON DELETE CASCADE,
  relationship_type TEXT NOT NULL, -- 'related_to', 'caused_by', 'depends_on', 'conflicts_with'
  strength REAL DEFAULT 1.0, -- 0.0 to 1.0
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMP NOT NULL DEFAULT NOW(),
  UNIQUE(source_memory_id, target_memory_id, relationship_type)
);

-- Memory access logs (audit trail)
CREATE TABLE memory_access_logs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  memory_id UUID NOT NULL REFERENCES memory_entries(id) ON DELETE CASCADE,
  accessed_by_agent_id UUID REFERENCES agents(id),
  accessed_by_user_id UUID REFERENCES users(id),
  access_type TEXT NOT NULL, -- 'read', 'write', 'update', 'delete'
  query_text TEXT,
  result_count INTEGER,
  accessed_at TIMESTAMP NOT NULL DEFAULT NOW()
);

-- Indexes
CREATE INDEX idx_memory_contexts_type_id ON memory_contexts(context_type, context_id);
CREATE INDEX idx_memory_entries_context ON memory_entries(context_id);
CREATE INDEX idx_memory_entries_type ON memory_entries(memory_type);
CREATE INDEX idx_memory_entries_agent ON memory_entries(source_agent_id);
CREATE INDEX idx_memory_relationships_source ON memory_relationships(source_memory_id);
CREATE INDEX idx_memory_relationships_target ON memory_relationships(target_memory_id);
CREATE INDEX idx_memory_access_logs_memory ON memory_access_logs(memory_id);

-- Vector similarity search index (pgvector)
CREATE INDEX idx_memory_entries_embedding ON memory_entries 
  USING ivfflat (embedding vector_cosine_ops) 
  WITH (lists = 100);
```

---

## ðŸ“¦ Step 1.4: Mem0 Installation & Configuration

### Package Installation

```json
// package.json additions
{
  "dependencies": {
    "mem0ai": "^1.0.3",
    "@pinecone-database/pinecone": "^2.0.0", // Optional: if using Pinecone
    "langchain": "^0.1.20" // For LangChain integration
  }
}
```

### Configuration File

```typescript
// server/config/mem0-config.ts
export interface Mem0Config {
  provider: 'postgresql' | 'pinecone' | 'qdrant';
  postgresql?: {
    host: string;
    port: number;
    database: string;
    user: string;
    password: string;
  };
  embedding: {
    provider: 'openai' | 'ollama' | 'local';
    model: string;
    dimensions: number;
  };
  graph: {
    enabled: boolean;
    maxDepth: number;
  };
}

export const mem0Config: Mem0Config = {
  provider: 'postgresql',
  postgresql: {
    host: process.env.DATABASE_HOST || 'localhost',
    port: parseInt(process.env.DATABASE_PORT || '5434'),
    database: process.env.DATABASE_NAME || 'rtpi_main',
    user: process.env.DATABASE_USER || 'rtpi',
    password: process.env.DATABASE_PASSWORD || 'rtpi',
  },
  embedding: {
    provider: process.env.EMBEDDING_PROVIDER || 'openai',
    model: 'text-embedding-ada-002',
    dimensions: 1536,
  },
  graph: {
    enabled: true,
    maxDepth: 3,
  },
};
```

---

## âœ… Step 1.5: Success Criteria

- [ ] Mem0 framework installed and configured
- [ ] Database schema migrated successfully
- [ ] Memory service layer implemented
- [ ] Basic CRUD operations tested
- [ ] Vector similarity search functional
- [ ] Graph relationships working
- [ ] Documentation complete
- [ ] Unit tests passing (>80% coverage)

---

## ðŸ“„ Deliverables

1. **Research Document:** `docs/enhancements/2.3/memory-system-research.md`
2. **Architecture Diagram:** `docs/enhancements/2.3/memory-architecture.png`
3. **Migration Script:** `migrations/0020_add_mem0_integration.sql`
4. **Service Implementation:** `server/services/memory-service.ts`
5. **Configuration:** `server/config/mem0-config.ts`
6. **API Routes:** `server/api/v1/memory.ts`
7. **Unit Tests:** `tests/unit/memory-service.test.ts`
8. **Integration Tests:** `tests/integration/memory-integration.test.ts`

---

## ðŸš€ Ready to Proceed?

Once you **toggle to Act mode**, I'll implement Phase 1 in baby steps:

1. Create migration script
2. Implement memory service
3. Add API routes
4. Write tests
5. Create documentation

Would you like me to proceed with Phase 1 implementation, or would you like to review/adjust this plan first?