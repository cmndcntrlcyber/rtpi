# Phase 3: Operations Management Automation - Detailed Plan

Building on **Phase 1's Memory System Foundation** and **Phase 2's Agent System Architecture**, Phase 3 wires the existing scanning infrastructure (BBOT, Nuclei, Nmap) into an event-driven automation cascade with operation lifecycle hooks.

---

## Phase 3 Overview

**Objective:** Automate the full scan pipeline from operation activation through vulnerability reporting, including automatic target creation from scan results, Nmap integration into the surface assessment pipeline, and operation lifecycle hooks.

**Duration Estimate:** 5-7 days

**Dependencies:**
- Phase 1 (Memory System Foundation) - for memory integration points
- Phase 2 (Agent System Architecture) - for message bus and reporter framework
- Existing BBOT/Nuclei executors operational
- Docker `rtpi-tools` container running

---

## Current State Analysis

### What Already Exists

| Component | Status | Location |
|-----------|--------|----------|
| Operations lifecycle (CRUD, status transitions) | FULLY IMPLEMENTED | `server/api/v1/operations.ts` |
| BBOT async scanning + asset discovery | FULLY IMPLEMENTED | `server/services/bbot-executor.ts` (763 lines) |
| Nuclei async scanning + CVE extraction | FULLY IMPLEMENTED | `server/services/nuclei-executor.ts` (606 lines) |
| Nmap scanning | PARTIAL - sync, targets only | `server/api/v1/targets.ts` (lines 118-239) |
| Target management (CRUD) | FULLY IMPLEMENTED | `server/api/v1/targets.ts` |
| Vulnerability tracking + AI enrichment | FULLY IMPLEMENTED | `server/api/v1/vulnerabilities.ts` |
| Surface assessment framework | FULLY IMPLEMENTED | `server/api/v1/surface-assessment.ts` (973 lines) |
| Workflow event handlers | BASIC (2 events) | `server/services/workflow-event-handlers.ts` |
| Scan scheduler | EXISTS BUT DISABLED | `server/services/scan-scheduler.ts` (CronJob commented out) |
| Operations Manager Agent | EXISTS | `server/services/operations-manager-agent.ts` |
| Reporter Agent Service | EXISTS | `server/services/reporter-agent-service.ts` |

### Critical Gaps

1. **No target auto-creation from scan results** - `discoveredAssets` and `targets` tables are completely disconnected. BBOT discovers assets but they never become scannable targets.
2. **Nmap not in surface assessment pipeline** - Only available as synchronous per-target scan. Results stored in target metadata, not in `discoveredAssets`/`discoveredServices`.
3. **Only 2 workflow event triggers** - `operation_created` and `surface_assessment_completed`. No pipeline cascade.
4. **No operation lifecycle automation** - Status transitions (active, paused, completed) don't trigger or cancel any scans.
5. **No vulnerability-specific reporter** - Generic reporter service exists but no vuln-focused polling/alerting.
6. **Scan scheduler disabled** - CronJob implementation commented out with TODO placeholders.

---

## Architecture Design

### Scan Pipeline Cascade

```
OPERATION ACTIVATED (human confirms status = "active")
        │
        ▼  (operation_activated event)
        │
┌───────────────────────────────────────────────────────┐
│ [BBOT Surface Scan]  (existing bbotExecutor)          │
│  - Discovers domains, IPs, URLs, services             │
│  - Stores to discoveredAssets + discoveredServices     │
└───────────────────┬───────────────────────────────────┘
                    │
                    ▼  (bbot_scan_completed event)
                    │
┌───────────────────────────────────────────────────────┐
│ [Target Auto-Creation Service]  (NEW)                 │
│  - Reads discoveredAssets for this operationId        │
│  - Creates targets rows, links via discoveredAssetId  │
│  - Deduplicates by value + operationId                │
└───────────────────┬───────────────────────────────────┘
                    │
                    ▼  (targets_auto_created event)
                    │
┌───────────────────────────────────────────────────────┐
│ [Nmap Port Scan]  (NEW async executor)                │
│  - Runs nmap against each new target                  │
│  - Stores results in discoveredServices               │
│  - XML output parsing for reliability                 │
└───────────────────┬───────────────────────────────────┘
                    │
                    ▼  (nmap_scan_completed event)
                    │
┌───────────────────────────────────────────────────────┐
│ [Nuclei Vulnerability Scan]  (existing nucleiExecutor)│
│  - Targets web ports found by nmap (80,443,8080,8443) │
│  - Creates vulnerabilities with CVE/CWE/CVSS          │
└───────────────────┬───────────────────────────────────┘
                    │
                    ▼  (nuclei_scan_completed event)
                    │
┌───────────────────────────────────────────────────────┐
│ [Vulnerability Reporter Agent]  (NEW)                 │
│  - Detects new critical/high vulnerabilities          │
│  - Reports to Operations Manager as questions         │
│  - Tracks remediation progress                        │
└───────────────────────────────────────────────────────┘
```

### Key Architectural Decisions

1. **Event bus stays on EventEmitter** - The `WorkflowEventHandlers` singleton is already the central event hub. New event types are added to it. Phase 2's `AgentMessageBus` takes over when implemented.

2. **Nmap executor follows BBOT/Nuclei pattern exactly** - Async fire-and-forget, `axScanResults` for tracking, `discoveredAssets`/`discoveredServices` for storage.

3. **Target auto-creation is a dedicated service** - Not embedded in any single executor. Responds to `bbot_scan_completed` events and converts discoveredAssets into targets.

4. **Pipeline status tracked on operations table** - New `pipelineStatus` JSON column tracks current phase, timing, and scan IDs per operation.

---

## Step 3.1: Database Schema Changes

### New Columns on `targets` Table

```typescript
// In shared/schema.ts, add to the targets table definition:
discoveredAssetId: uuid("discovered_asset_id")
  .references(() => discoveredAssets.id, { onDelete: "set null" }),
autoCreated: boolean("auto_created").notNull().default(false),
sourceScanId: uuid("source_scan_id")
  .references(() => axScanResults.id, { onDelete: "set null" }),
```

These columns link a target back to the discoveredAsset and scan that originated it, establishing the currently-missing relationship between the `discoveredAssets` and `targets` tables.

### New Columns on `discoveredAssets` Table

```typescript
// In shared/schema.ts, add to discoveredAssets table:
targetId: uuid("target_id")
  .references(() => targets.id, { onDelete: "set null" }),
```

Back-reference for the bidirectional link.

### New Columns on `operations` Table

```typescript
// In shared/schema.ts, add to operations table:
pipelineStatus: json("pipeline_status"),
// Stores: { currentPhase, phases: [{name, status, startedAt, completedAt, scanId}], lastUpdated }
automationEnabled: boolean("automation_enabled").notNull().default(true),
```

### Asset Type to Target Type Mapping

The `assetTypeEnum` and `targetTypeEnum` values differ slightly:

| assetTypeEnum | targetTypeEnum | Mapping |
|---------------|----------------|---------|
| `host` | `ip` | Host assets map to IP targets |
| `domain` | `domain` | Direct mapping |
| `ip` | `ip` | Direct mapping |
| `network` | `network` | Direct mapping |
| `url` | `url` | Direct mapping |

### Migration SQL

```sql
-- migrations/0008_phase3_target_auto_creation.sql

ALTER TABLE targets
  ADD COLUMN discovered_asset_id UUID REFERENCES discovered_assets(id) ON DELETE SET NULL,
  ADD COLUMN auto_created BOOLEAN NOT NULL DEFAULT false,
  ADD COLUMN source_scan_id UUID REFERENCES ax_scan_results(id) ON DELETE SET NULL;

ALTER TABLE discovered_assets
  ADD COLUMN target_id UUID REFERENCES targets(id) ON DELETE SET NULL;

ALTER TABLE operations
  ADD COLUMN pipeline_status JSONB,
  ADD COLUMN automation_enabled BOOLEAN NOT NULL DEFAULT true;

CREATE INDEX idx_targets_discovered_asset ON targets(discovered_asset_id);
CREATE INDEX idx_targets_auto_created ON targets(auto_created);
CREATE INDEX idx_discovered_assets_target ON discovered_assets(target_id);
CREATE INDEX idx_operations_automation ON operations(automation_enabled);
```

---

## Step 3.2: Target Auto-Creation Service

### Purpose

The #1 gap in the current system. After BBOT scans discover assets, they sit in `discovered_assets` with no connection to `targets`. This service bridges the two.

### Implementation File

```
server/services/target-auto-creation-service.ts (NEW)
```

### Interface

```typescript
interface AutoCreationResult {
  created: number;
  skipped: number;
  targetIds: string[];
}

class TargetAutoCreationService {
  /**
   * Convert discoveredAssets to targets for a given operation and scan.
   * - Queries discoveredAssets WHERE operationId AND targetId IS NULL
   * - Deduplicates: skips if target with same value+operationId already exists
   * - Maps assetTypeEnum -> targetTypeEnum
   * - Sets autoCreated=true, discoveredAssetId, sourceScanId
   * - Updates discoveredAsset.targetId back-reference
   */
  async autoCreateTargetsFromAssets(
    operationId: string,
    scanId: string
  ): Promise<AutoCreationResult>;

  /**
   * Link existing manually-created targets to discoveredAssets by matching value.
   * Useful for operations where targets were created before scanning.
   */
  async linkExistingTargetsToAssets(operationId: string): Promise<number>;

  /**
   * Map asset type enum to target type enum.
   */
  private mapAssetTypeToTargetType(
    assetType: 'host' | 'domain' | 'ip' | 'network' | 'url'
  ): 'ip' | 'domain' | 'url' | 'network' | 'range';
}
```

### Key Behaviors

- Target name derived from asset value (e.g., "192.168.1.1" or "sub.example.com")
- Uses `onConflictDoNothing()` pattern from `bbot-executor.ts` for idempotency
- Default target priority: 3 (medium)
- Tags auto-created targets with `['auto-created', discoveryMethod]`
- Skips assets with status `down` or `unreachable`

---

## Step 3.3: Event-Driven Pipeline Wiring

### Enhanced Workflow Event Handlers

**File:** `server/services/workflow-event-handlers.ts` (MODIFY)

#### New Configuration Flags

```typescript
interface WorkflowEventHandlerConfig {
  // Existing:
  enableAutoTrigger: boolean;
  enableSurfaceAssessmentOnOperationCreate: boolean;
  enableWebHackerOnSurfaceAssessmentComplete: boolean;
  requireScopeForSurfaceAssessment: boolean;

  // New Phase 3 flags:
  enableTargetAutoCreation: boolean;       // default: true
  enableNmapOnTargetCreation: boolean;     // default: true
  enableNucleiOnNmapCompletion: boolean;   // default: true
  enableVulnReporterOnNucleiComplete: boolean; // default: true
}
```

#### New Event Handlers

**handleBBOTScanCompleted(operationId, scanId, userId):**
1. Call `targetAutoCreationService.autoCreateTargetsFromAssets(operationId, scanId)`
2. Emit `targets_auto_created` with `{ operationId, scanId, targetCount }`
3. Update `operations.pipelineStatus` with target creation results
4. Then call existing `handleSurfaceAssessmentCompleted()` (preserves current web hacker flow)

**handleTargetsAutoCreated(operationId, scanId, userId):**
1. Query auto-created targets (IP and domain types) for this operation
2. Batch targets into groups (max 10 per nmap scan for performance)
3. Call `nmapExecutor.startScan()` for each batch
4. Update `operations.pipelineStatus` to `currentPhase: 'nmap'`

**handleNmapScanCompleted(operationId, scanId, userId):**
1. Query `discoveredServices` for web ports (80, 443, 8080, 8443, 8888, 3000)
2. Build target URLs from `host:port` pairs
3. Call `nucleiExecutor.startScan()` against web targets
4. Update `operations.pipelineStatus` to `currentPhase: 'nuclei'`

**handleNucleiScanCompleted(operationId, scanId, userId):**
1. Emit `nuclei_scan_completed` event
2. Trigger vulnerability reporter agent poll
3. Update `operations.pipelineStatus` to `currentPhase: 'reporting'`

#### Modify Existing handleScanCompleted()

Current behavior (line 300-315):
```typescript
async handleScanCompleted(scanId, scanType, operationId, userId) {
  this.emit('scan_completed', { scanId, scanType, operationId, userId });
  if (scanType === 'bbot') {
    await this.handleSurfaceAssessmentCompleted(operationId, userId);
  }
}
```

New behavior:
```typescript
async handleScanCompleted(scanId, scanType, operationId, userId) {
  this.emit('scan_completed', { scanId, scanType, operationId, userId });

  if (scanType === 'bbot') {
    // Phase 3: Auto-create targets before triggering web hacker
    if (this.config.enableTargetAutoCreation) {
      await this.handleBBOTScanCompleted(operationId, scanId, userId);
    }
    await this.handleSurfaceAssessmentCompleted(operationId, userId);
  } else if (scanType === 'nmap') {
    await this.handleNmapScanCompleted(operationId, scanId, userId);
  } else if (scanType === 'nuclei') {
    await this.handleNucleiScanCompleted(operationId, scanId, userId);
  }
}
```

#### New Workflow Templates

Add to `DEFAULT_WORKFLOW_TEMPLATES`:

```typescript
{
  name: "Target Auto-Creation Workflow",
  description: "Automatically creates targets from discovered assets after BBOT scan completion.",
  triggerEvent: "bbot_scan_completed",
  requiredCapabilities: ["target_creation"],
  configuration: {
    maxParallelAgents: 1,
    timeoutPerPhase: 300000,
    retryPolicy: { maxRetries: 2, backoffMultiplier: 2 },
    fallbackBehavior: "skip",
  },
  isActive: true,
},
{
  name: "Nmap Port Scan Workflow",
  description: "Runs Nmap port scans against auto-created targets to discover services.",
  triggerEvent: "targets_auto_created",
  requiredCapabilities: ["port_scanning"],
  configuration: {
    maxParallelAgents: 3,
    timeoutPerPhase: 1800000,
    retryPolicy: { maxRetries: 2, backoffMultiplier: 2 },
    fallbackBehavior: "skip",
  },
  isActive: true,
},
{
  name: "Nuclei Post-Nmap Workflow",
  description: "Runs Nuclei vulnerability scans against web services discovered by Nmap.",
  triggerEvent: "nmap_scan_completed",
  requiredCapabilities: ["vulnerability_scanning"],
  configuration: {
    maxParallelAgents: 3,
    timeoutPerPhase: 7200000,
    retryPolicy: { maxRetries: 1, backoffMultiplier: 1 },
    fallbackBehavior: "skip",
  },
  isActive: true,
},
{
  name: "Vulnerability Reporting Workflow",
  description: "Reports new vulnerabilities to Operations Manager after Nuclei scan completion.",
  triggerEvent: "nuclei_scan_completed",
  requiredCapabilities: ["vulnerability_reporting"],
  configuration: {
    maxParallelAgents: 1,
    timeoutPerPhase: 300000,
    retryPolicy: { maxRetries: 1, backoffMultiplier: 1 },
    fallbackBehavior: "skip",
  },
  isActive: true,
},
```

---

## Step 3.4: Nmap Async Executor

### Purpose

Bring Nmap into the surface assessment pipeline alongside BBOT and Nuclei. Currently Nmap is only available as a synchronous per-target scan in `server/api/v1/targets.ts` with results stored in target metadata. The new executor follows the BBOT/Nuclei async pattern.

### Implementation File

```
server/services/nmap-executor.ts (NEW)
```

### Interface

```typescript
interface NmapOptions {
  ports?: string;              // e.g., '1-65535' or '1-1024' (default: '1-1024')
  timing?: string;             // T0-T5 (default: 'T4')
  serviceDetection?: boolean;  // -sV (default: true)
  osDetection?: boolean;       // -O (default: false)
  scripts?: string[];          // --script (e.g., ['http-headers', 'ssl-enum-ciphers'])
  extraArgs?: string[];        // Additional arguments
}

interface NmapHost {
  ip: string;
  hostname?: string;
  status: string;
  ports: NmapPort[];
  os?: string;
}

interface NmapPort {
  port: number;
  protocol: string;   // tcp, udp
  state: string;      // open, filtered, closed
  service: string;    // http, ssh, etc.
  version?: string;
  banner?: string;
}

interface NmapResult {
  hosts: NmapHost[];
  raw: string;
}

class NmapExecutor {
  /**
   * Start async nmap scan. Returns immediately with scanId.
   * Follows bbotExecutor.startScan() pattern exactly.
   */
  async startScan(
    targets: string[],
    options: NmapOptions,
    operationId: string,
    userId: string
  ): Promise<{ scanId: string }>;

  /**
   * Internal: runs the actual scan asynchronously.
   */
  private async runScan(
    scanId: string,
    targets: string[],
    options: NmapOptions,
    operationId: string
  ): Promise<{ hostsCount: number; servicesCount: number }>;

  /**
   * Parse nmap XML output (-oX -) into structured data.
   */
  private parseXmlOutput(stdout: string): NmapResult;

  /**
   * Store results in discoveredAssets and discoveredServices tables.
   * Uses discoveryMethod: 'nmap'.
   */
  private async storeResults(
    results: NmapResult,
    operationId: string,
    scanId: string
  ): Promise<{ assetsCount: number; servicesCount: number }>;
}

export const nmapExecutor = new NmapExecutor();
```

### Execution Details

- **Docker container:** `rtpi-tools` (same as BBOT/Nuclei)
- **Command:** `sudo nmap -Pn -sV -oX - <targets>` (XML output to stdout)
- **Keepalive:** 30 minutes (matching BBOT pattern)
- **Result storage:**
  - New hosts → `discoveredAssets` with `discoveryMethod: 'nmap'`, `type: 'ip'`
  - Open ports → `discoveredServices` with service name, version, banner
  - Uses `onConflictDoNothing()` for deduplication
- **axScanResults tracking:** `toolName: 'nmap'`, status progression: pending → running → completed/failed
- **Emits:** `handleScanCompleted(scanId, 'nmap', operationId, userId)` on `workflowEventHandlers`

### Differences from Existing Nmap in targets.ts

| Aspect | Current (targets.ts) | New (nmap-executor.ts) |
|--------|---------------------|----------------------|
| Execution | Synchronous | Async fire-and-forget |
| Scope | Single target | Multiple targets per scan |
| Output parsing | Text stdout | XML (`-oX -`) for reliability |
| Storage | Target metadata JSON | discoveredAssets + discoveredServices |
| Tracking | None | axScanResults table |
| Pipeline | Standalone | Emits events for cascade |
| Timeout | Per-request | Database keepalive (30 min) |

---

## Step 3.5: Operation Lifecycle Automation

### Purpose

Connect operation status transitions to automated pipeline actions. Currently, changing an operation's status has no side effects.

### Implementation File

```
server/services/operation-lifecycle-automation.ts (NEW)
```

### Interface

```typescript
class OperationLifecycleAutomation {
  /**
   * Called when operation status changes to "active".
   * - Checks operation.automationEnabled and operation.scope
   * - Triggers BBOT surface scan via workflowEventHandlers
   * - Sets pipelineStatus = { currentPhase: 'bbot', ... }
   */
  async handleOperationActivated(operationId: string, userId: string): Promise<void>;

  /**
   * Called when operation status changes to "paused".
   * - Finds running axScanResults for this operation
   * - Sets their status to 'cancelled'
   * - Sets pipelineStatus.currentPhase = 'paused'
   */
  async handleOperationPaused(operationId: string): Promise<void>;

  /**
   * Called when operation status changes to "completed" or "cancelled".
   * - Cancels any running scans
   * - Sets pipelineStatus.currentPhase = 'completed'
   */
  async handleOperationCompleted(operationId: string, userId: string): Promise<void>;
}

export const operationLifecycleAutomation = new OperationLifecycleAutomation();
```

### Hooks in Operations API

**File:** `server/api/v1/operations.ts` (MODIFY)

```typescript
// POST /:id/start (line 192) - After status update:
await operationLifecycleAutomation.handleOperationActivated(id, user.id);

// PATCH /:id/status (line 250) - After status update:
if (status === 'active') {
  await operationLifecycleAutomation.handleOperationActivated(id, user.id);
} else if (status === 'paused') {
  await operationLifecycleAutomation.handleOperationPaused(id);
} else if (status === 'completed' || status === 'cancelled') {
  await operationLifecycleAutomation.handleOperationCompleted(id, user.id);
}
```

### Pipeline Status JSON Structure

```typescript
interface PipelineStatus {
  currentPhase: 'idle' | 'bbot' | 'target_creation' | 'nmap' | 'nuclei' | 'reporting' | 'paused' | 'completed';
  automationEnabled: boolean;
  phases: Array<{
    name: string;
    status: 'pending' | 'running' | 'completed' | 'failed' | 'skipped';
    scanId?: string;
    startedAt?: string;
    completedAt?: string;
    resultSummary?: Record<string, number>;
  }>;
  lastUpdated: string;
}
```

---

## Step 3.6: Vulnerability Reporter Agent

### Purpose

A specialized reporter that monitors vulnerability state changes, detects new critical/high findings, and reports to the Operations Manager. Follows the existing `ReporterAgentService` polling pattern.

### Implementation File

```
server/services/vulnerability-reporter-agent.ts (NEW)
```

### Interface

```typescript
interface VulnReporterConfig {
  pollIntervalMs: number;           // Default: 60000 (1 minute)
  criticalAlertImmediate: boolean;  // Submit question immediately for criticals
  trackStatusChanges: boolean;      // Detect open->fixed, etc.
  trackSeverityChanges: boolean;    // Detect severity re-classifications
}

interface VulnChangeEvent {
  type: 'new_vulnerability' | 'severity_changed' | 'status_changed' | 'remediated';
  vulnerabilityId: string;
  operationId: string;
  severity: string;
  previousValue?: string;
  newValue?: string;
  timestamp: Date;
}

class VulnerabilityReporterAgent extends EventEmitter {
  private lastPollTimestamp: Date;
  private pollInterval: NodeJS.Timeout | null;

  async initialize(): Promise<void>;
  async startPolling(): Promise<void>;
  async stopPolling(): Promise<void>;

  /**
   * Main polling loop.
   * - Queries vulnerabilities WHERE discoveredAt > lastPollTimestamp
   * - Detects new critical/high vulns
   * - For each: creates reporterQuestion for Ops Manager
   * - Emits 'vulnerability_report_submitted'
   */
  private async pollVulnerabilities(): Promise<VulnChangeEvent[]>;
  private async detectNewVulnerabilities(since: Date): Promise<VulnChangeEvent[]>;
  private async detectStatusChanges(since: Date): Promise<VulnChangeEvent[]>;
  private async submitReportToOpsManager(events: VulnChangeEvent[]): Promise<void>;
  async getStatus(): Promise<{ isPolling: boolean; lastPoll: Date; eventsDetected: number }>;
}

export const vulnerabilityReporterAgent = new VulnerabilityReporterAgent();
```

### Lifecycle

```
1. INITIALIZATION
   └─> Register in reporters table with pageId: 'vulnerabilities'

2. POLLING CYCLE (every 60 seconds)
   ├─> Query vulnerabilities WHERE discoveredAt > lastPollTimestamp
   ├─> Detect new critical/high vulns
   ├─> Detect status changes (open -> fixed, etc.)
   ├─> For each critical: create reporterQuestion to Ops Manager
   ├─> Emit 'vulnerability_report_submitted'
   └─> Update lastPollTimestamp

3. INITIALIZATION IN AGENT SYSTEM
   └─> Added to initializeAgentSystem() in workflow-event-handlers.ts
   └─> Stopped in shutdownAgentSystem()
```

---

## Step 3.7: Scan Scheduler Activation

### Purpose

The `ScanScheduler` at `server/services/scan-scheduler.ts` has fully-structured code with CronJob implementation commented out. Phase 3 activates it.

### Changes

**File:** `server/services/scan-scheduler.ts` (MODIFY)

1. **Install dependency:** `npm install cron @types/cron`
2. **Uncomment** `CronJob` import (line 13)
3. **Uncomment** CronJob creation in `addSchedule()` (lines 108-129)
4. **Uncomment** CronJob-based `updateNextRun()` (lines 255-264)
5. **Wire** `executeBBOTScan()` to call `bbotExecutor.startScan(...)` (replace TODO at line 211)
6. **Wire** `executeNucleiScan()` to call `nucleiExecutor.startScan(...)` (replace TODO at line 239)
7. **Add** `executeNmapScan()` method calling `nmapExecutor.startScan(...)`
8. **Add** nmap to `ScanSchedule.toolConfig` interface:

```typescript
toolConfig: {
  bbot?: { targets: string[]; flags?: string[]; config?: Record<string, any> };
  nuclei?: { targets: string[]; templates?: string[]; severity?: string[]; config?: Record<string, any> };
  nmap?: { targets: string[]; ports?: string; timing?: string; config?: Record<string, any> }; // NEW
};
```

---

## Step 3.8: Automation Pipeline API

### Purpose

REST endpoints for pipeline status monitoring, manual triggers, and configuration.

### Implementation File

```
server/api/v1/automation-pipeline.ts (NEW)
```

### Endpoints

| Method | Path | Description |
|--------|------|-------------|
| `GET` | `/:operationId/status` | Pipeline status (current phase, scan IDs, timing) |
| `POST` | `/:operationId/trigger` | Manual trigger. Body: `{startFrom?: 'bbot'\|'nmap'\|'nuclei'}` |
| `POST` | `/:operationId/pause` | Pause pipeline (cancels pending scans) |
| `POST` | `/:operationId/resume` | Resume pipeline from where it stopped |
| `GET` | `/:operationId/targets/auto-created` | List auto-created targets with source asset info |
| `POST` | `/:operationId/targets/auto-create` | Manual target auto-creation from existing discoveredAssets |
| `GET` | `/config` | Get current automation configuration |
| `PATCH` | `/config` | Update automation configuration |

### Registration

**File:** `server/index.ts` (MODIFY)

```typescript
import automationPipelineRoutes from "./api/v1/automation-pipeline";
// ...
app.use("/api/v1/automation-pipeline", automationPipelineRoutes);
```

---

## Deliverables

### New Files (6)

```
server/services/target-auto-creation-service.ts
server/services/nmap-executor.ts
server/services/vulnerability-reporter-agent.ts
server/services/operation-lifecycle-automation.ts
server/api/v1/automation-pipeline.ts
migrations/0008_phase3_target_auto_creation.sql
```

### Modified Files (5)

```
shared/schema.ts                                   (add columns to targets, discoveredAssets, operations)
server/services/workflow-event-handlers.ts          (add event handlers, config flags, templates)
server/services/scan-scheduler.ts                   (activate CronJob, wire to real executors, add nmap)
server/api/v1/operations.ts                         (hook status transitions to lifecycle automation)
server/index.ts                                     (register automation-pipeline routes)
```

---

## Integration with Phase 1 (Memory) and Phase 2 (Agents)

### Phase 1 (Mem0 Memory System)

Each automation step includes `// Phase 1: store memory entry` placeholder comments at:
- Target auto-creation events (memory type: `event`)
- Pipeline phase transitions (memory type: `event`)
- Vulnerability reporter insights (memory type: `insight`)
- Nmap service discoveries (memory type: `fact`)

No hard dependency — actual `MemoryService` calls added once Phase 1 is implemented.

### Phase 2 (Agent System Architecture)

- **Vulnerability Reporter Agent** uses `EventEmitter` pattern in Phase 3. When Phase 2's `AgentMessageBus` is available, it migrates to formal `AgentMessage` protocol.
- Events emitted in Phase 3 (`targets_auto_created`, `nmap_scan_completed`, etc.) are designed to wrap into Phase 2's `AgentMessage.messageType: 'alert'` format.
- The Operations Manager's reception of vulnerability reports uses the existing `reporterQuestions` table, which Phase 2 formalizes.

### v2.4 Boundary

Phase 3 does NOT implement:
- Dual-agency system (v2.4/v2.5 Agentic Autonomy)
- Review Agent, QA Agent, or Technical Report Writer Agent
- SysReptor integration
- Contrarian validation loop (v2.4 System-2)

---

## Implementation Order (Baby Steps)

| Step | Task | Duration | Dependencies |
|------|------|----------|--------------|
| 1 | Schema changes (`shared/schema.ts` + migration SQL) | 1-2 hours | None |
| 2 | Target auto-creation service | 3-4 hours | Step 1 |
| 3 | Wire BBOT completion → target auto-creation in `workflow-event-handlers.ts` | 1-2 hours | Step 2 |
| 4 | Nmap async executor | 4-5 hours | Step 1 |
| 5 | Wire target creation → nmap → nuclei pipeline | 1-2 hours | Steps 3, 4 |
| 6 | Operation lifecycle automation + hooks in `operations.ts` | 2-3 hours | Step 5 |
| 7 | Vulnerability reporter agent | 3-4 hours | Step 5 |
| 8 | Scan scheduler activation | 2-3 hours | Step 4 |
| 9 | Automation pipeline API + registration | 2-3 hours | Steps 5, 6 |
| 10 | Integration testing (full pipeline end-to-end) | 2-3 hours | All |

---

## Success Criteria

- [ ] After BBOT scan completes, targets are auto-created in `targets` table with `auto_created=true` and `discovered_asset_id` populated
- [ ] Bidirectional link: `discoveredAssets.targetId` and `targets.discoveredAssetId` cross-reference correctly
- [ ] Nmap runs asynchronously, stores results in `discoveredServices` (not target metadata), creates `axScanResults` with `toolName: 'nmap'`
- [ ] Full pipeline cascade: activate operation → BBOT → auto-create targets → nmap → nuclei, without manual intervention
- [ ] Pausing an operation cancels running scans; completing stops the pipeline
- [ ] New critical vulnerabilities detected within one polling cycle and reported to Operations Manager
- [ ] CronJob-based scan scheduling works end-to-end
- [ ] `GET /api/v1/automation-pipeline/:operationId/status` returns current phase, timing, and scan IDs
- [ ] No regressions: existing manual scan endpoints, surface assessment agent, and web hacker agent continue to work
- [ ] All new services follow existing patterns (async fire-and-forget, Docker execution, EventEmitter)

---

## Ready to Proceed?

This plan establishes the complete operations automation pipeline that enables:
- **Automatic target discovery** from BBOT scan results
- **Full scan cascade** from surface assessment through vulnerability scanning
- **Operation lifecycle control** that starts, pauses, and completes pipelines
- **Real-time vulnerability alerting** via the reporter agent
- **Scheduled recurring scans** via activated CronJob scheduler

**Next Steps:**
1. Review this Phase 3 plan
2. Confirm scope and priorities
3. Toggle to Act mode to begin implementation

Phases 4-7 (UI/UX Reorganization, Framework Integration, Reporting System, Topology & Visualization) will be planned in subsequent documents.
